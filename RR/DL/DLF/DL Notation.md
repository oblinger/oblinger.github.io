- [[ML Notation]] 
-  [[NG Notation]], 
- [[Transformers]],
- [[DL Theory]], 

==> [Wiki Attention](https://en.wikipedia.org/wiki/Attention_(machine_learning)) 
- x_i = Sequence of input symbols
- X = Word Embedding Matrix
- Q_w = Query. (see [[RASA]] for intuition)
- K_w = Key
- V_w = Value

![](https://miro.medium.com/v2/resize:fit:677/1*KJO94OuI6AVaGOBmHuf_nA.png)

[[Feed Forward Layer]] -

[[Attention]] - 