

Extrapolating from the range of existing intelligence suggests two types of superintelligence, which we will call quantitative superintelligence and qualitative superintelligence:
- ***quantitative superintelligence*** is the simple amplification of existing intelligence by replicating it in time and space -- so performing the same thinking faster and performing many copies of the same thinking with loose coordination of the progress and results from this thinking.
- ***qualitative superintelligence*** is thinking of a different kind that is capable of solving problems that are unsolvable given indefinite amounts of time and replication of the lower form of thinking.


The ability to solve ever greater numbers of sudoku puzzles within a fixed time window would represent a simple case of quantitative superintelligence.  While the discovery/creation of calculus represents a qualitative superintelligence relative to normal human intelligence.  Most people could never accomplish this, even given a lifetime of effort.


The salient aspect of superintelligence is its ability to confer relative advantage as compared with other intelligence within a group.  There are two types of relative advantage: ***quantitative and qualitative advantage***, each obtained from their corresponding type of superintelligence.  So, a quantitative advantage might be obtained by thinking more and longer, while a qualitative advantage is only obtained by thinking differently.


Both kinds of superintelligence seem plausible with an AGI, the former quantitative superintelligence seems a virtual certainty relative to unaided humans, given the nature of silicon thinking vs biological thinking.  

If we consider the quantitative advantage of one computational AI as compared with its peers, this seems likely to remain limited in size as quantitative intelligence increases, assuming the relative computational resources are reasonably balanced across different computational AIs.  We see diminishing returns with ever greater amounts of the same kind of thinking. Thus, it seems unlikely that one AI would arrive at a large quantitative advantage relative to others during this progression.

The qualitative advantage of computational AIs over unaided humans should grow arbitrarily large over time.


Qualitative advantages between AIs are much harder for us to reason about.  Their value depends upon the nature of the as-yet-undiscovered advancements.  ([[No_Fast_Takeoff]] for)



