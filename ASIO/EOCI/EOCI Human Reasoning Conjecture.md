Human Reasoning Conjecture

- We can simplify human reasoning as a combination of Type-I, Type_II, and Agentic Control.
- We further notice that human appear to repeatedly be performing Type-I reasoning as they are performing type-II reasoning, it appears to be a sub-component.
- Current LLM technology performs similarly to human Type-I reasoning.
- A tunable trainable agentic control having a fixed modest structure seems it could approximate human reasoning.
- Human Type-II reasoning can operate effectively over periods of minutes to years or a lifetime.

- Achieving human-like type-II reasoning requires 
	- Train new Type-II strategies 
	- Being able to induce and operate over novel representations post training

The largest gap is achieving type-II reasoning, but it seems plausible that an algorithm no more complex than the transformer used for Type-I reasoning will be all that is required, and such could be developed anytime in the next years.


